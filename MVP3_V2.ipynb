{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNkuqMDOjymU9AVpEsv5LTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrelmsunb/andrelmspuc3/blob/main/MVP3_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8r0qWgeL9gt"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 1. CONFIGURAÇÃO INICIAL E IMPORTAÇÃO DAS BIBLIOTECAS\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CARREGAMENTO E DEFINIÇÃO DO PROBLEMA\n",
        "# ==============================================================================\n",
        "# Contexto: O objetivo é classificar vinhos como \"bons\" ou \"ruins\" com base\n",
        "# em suas características físico-químicas.\n",
        "\n",
        "# Carregando o dataset de vinhos tintos do repositório da UCI.\n",
        "# O \";\" é usado como separador neste arquivo.\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "data = pd.read_csv(url, sep=';' )\n",
        "\n",
        "print(\"\\nAmostra do Dataset Original:\")\n",
        "print(data.head())\n",
        "\n",
        "# Definição do Problema: Transformando em um problema de classificação binária.\n",
        "# A qualidade é uma nota de 0 a 10. Vamos definir vinhos com nota >= 7 como \"bons\" (classe 1)\n",
        "# e os demais como \"ruins\" (classe 0).\n",
        "data['quality_cat'] = np.where(data['quality'] >= 7, 1, 0)\n",
        "\n",
        "# Separando as features (X) e o alvo (y)\n",
        "X = data.drop(['quality', 'quality_cat'], axis=1)\n",
        "y = data['quality_cat']\n",
        "\n",
        "print(\"\\nDistribuição das classes (0 = Ruim, 1 = Bom):\")\n",
        "print(y.value_counts())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. PREPARAÇÃO DOS DADOS\n",
        "# ==============================================================================\n",
        "# 3.1. Separação em Treino e Teste\n",
        "# Usamos stratify=y para garantir que a proporção de vinhos bons/ruins\n",
        "# seja a mesma nos conjuntos de treino e teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nFormato dos dados de treino: {X_train.shape}\")\n",
        "print(f\"Formato dos dados de teste: {X_test.shape}\")\n",
        "\n",
        "# 3.2. Padronização dos Dados (Opcional, para modelos sensíveis à escala)\n",
        "# Embora o Random Forest não precise, é uma boa prática ter os dados padronizados\n",
        "# para comparar com outros modelos, como a Regressão Logística.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nDados padronizados com sucesso.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. MODELAGEM E TREINAMENTO\n",
        "# ==============================================================================\n",
        "# 4.1. Modelo Baseline: Regressão Logística\n",
        "# Um modelo simples para termos uma base de comparação.\n",
        "print(\"\\n--- Treinando Modelo Baseline: Regressão Logística ---\")\n",
        "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "log_reg.fit(X_train_scaled, y_train) # Usamos os dados escalados aqui\n",
        "\n",
        "# 4.2. Modelo Principal: Random Forest Classifier\n",
        "print(\"\\n--- Treinando Modelo Principal: Random Forest ---\")\n",
        "rf_initial = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
        "rf_initial.fit(X_train, y_train) # Não precisa de dados escalados\n",
        "\n",
        "# 4.3. Análise de Feature Importance do Random Forest\n",
        "print(\"\\nAnalisando a importância das features...\")\n",
        "importances = rf_initial.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
        "plt.title('Importância das Features - Random Forest Inicial')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. OTIMIZAÇÃO DE HIPERPARÂMETROS (GRIDSEARCHCV)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Otimizando o Random Forest com GridSearchCV ---\")\n",
        "# Definindo a grade de parâmetros para testar\n",
        "param_grid = {\n",
        "    'n_estimators': [150, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Configurando o GridSearchCV com validação cruzada (cv=5)\n",
        "# n_jobs=-1 usa todos os processadores disponíveis para acelerar a busca\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           n_jobs=-1,\n",
        "                           scoring='f1_weighted', # Métrica de otimização\n",
        "                           verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nMelhores hiperparâmetros encontrados: {grid_search.best_params_}\")\n",
        "\n",
        "# O melhor modelo já treinado está em grid_search.best_estimator_\n",
        "rf_optimized = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. AVALIAÇÃO FINAL E COMPARAÇÃO\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Avaliação Final dos Modelos no Conjunto de Teste ---\")\n",
        "\n",
        "# Fazendo previsões com todos os modelos\n",
        "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
        "y_pred_rf_initial = rf_initial.predict(X_test)\n",
        "y_pred_rf_optimized = rf_optimized.predict(X_test)\n",
        "\n",
        "# 6.1. Relatórios de Classificação\n",
        "print(\"\\nRelatório de Classificação - Regressão Logística:\")\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "print(\"\\nRelatório de Classificação - Random Forest Inicial:\")\n",
        "print(classification_report(y_test, y_pred_rf_initial))\n",
        "\n",
        "print(\"\\nRelatório de Classificação - Random Forest Otimizado:\")\n",
        "print(classification_report(y_test, y_pred_rf_optimized))\n",
        "\n",
        "# 6.2. Tabela Comparativa de Resultados\n",
        "# Usamos o 'f1-score' com 'weighted avg' para uma comparação justa em dados desbalanceados\n",
        "results = {\n",
        "    \"Modelo\": [\"Regressão Logística\", \"Random Forest Inicial\", \"Random Forest Otimizado\"],\n",
        "    \"Acurácia\": [\n",
        "        accuracy_score(y_test, y_pred_log_reg),\n",
        "        accuracy_score(y_test, y_pred_rf_initial),\n",
        "        accuracy_score(y_test, y_pred_rf_optimized)\n",
        "    ],\n",
        "    \"F1-Score (Ponderado)\": [\n",
        "        float(classification_report(y_test, y_pred_log_reg, output_dict=True)['weighted avg']['f1-score']),\n",
        "        float(classification_report(y_test, y_pred_rf_initial, output_dict=True)['weighted avg']['f1-score']),\n",
        "        float(classification_report(y_test, y_pred_rf_optimized, output_dict=True)['weighted avg']['f1-score'])\n",
        "    ]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n--- Tabela Comparativa de Performance ---\\n\")\n",
        "print(results_df.round(3))\n",
        "\n",
        "# 6.3. Análise de Overfitting do Melhor Modelo\n",
        "# Comparamos a performance no treino vs. no teste\n",
        "train_score = rf_optimized.score(X_train, y_train)\n",
        "test_score = rf_optimized.score(X_test, y_test)\n",
        "\n",
        "print(\"\\n--- Análise de Overfitting (Modelo Otimizado) ---\")\n",
        "print(f\"Pontuação no conjunto de Treino: {train_score:.3f}\")\n",
        "print(f\"Pontuação no conjunto de Teste:  {test_score:.3f}\")\n",
        "\n",
        "if train_score > test_score + 0.1:\n",
        "    print(\"\\nAlerta: Diferença significativa entre treino e teste. Pode haver overfitting.\")\n",
        "else:\n",
        "    print(\"\\nO modelo parece ter uma boa generalização.\")\n",
        "\n"
      ]
    }
  ]
}